{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301e8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b27c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://raw.githubusercontent.com/wongwara/Jobseeker_Baymax/d9d7fc4753ca407eba5423da6e1101e042b216a8/dataset/final_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613d9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3308b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1612f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 638 entries, 0 to 637\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             638 non-null    int64  \n",
      " 1   jobClassification      638 non-null    int64  \n",
      " 2   state                  638 non-null    int64  \n",
      " 3   teaser                 540 non-null    object \n",
      " 4   workType               638 non-null    int64  \n",
      " 5   min_salary             638 non-null    int64  \n",
      " 6   max_salary             638 non-null    int64  \n",
      " 7   isRightToWorkRequired  638 non-null    int64  \n",
      " 8   desktopAdTemplate      537 non-null    object \n",
      " 9   Python                 638 non-null    int64  \n",
      " 10  SQL                    638 non-null    int64  \n",
      " 11  R                      638 non-null    int64  \n",
      " 12  Tableau                638 non-null    int64  \n",
      " 13  SAS                    638 non-null    int64  \n",
      " 14  Matlab                 638 non-null    int64  \n",
      " 15  Hadoop                 638 non-null    int64  \n",
      " 16  Spark                  638 non-null    int64  \n",
      " 17  Java                   638 non-null    int64  \n",
      " 18  Scala                  638 non-null    int64  \n",
      " 19  recruiter              638 non-null    int64  \n",
      " 20  state_encoded          638 non-null    int64  \n",
      " 21  salary_section         638 non-null    object \n",
      " 22  salary_section_enc     638 non-null    float64\n",
      "dtypes: float64(1), int64(19), object(3)\n",
      "memory usage: 114.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a863e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>jobClassification</th>\n",
       "      <th>state</th>\n",
       "      <th>teaser</th>\n",
       "      <th>workType</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>isRightToWorkRequired</th>\n",
       "      <th>desktopAdTemplate</th>\n",
       "      <th>Python</th>\n",
       "      <th>...</th>\n",
       "      <th>SAS</th>\n",
       "      <th>Matlab</th>\n",
       "      <th>Hadoop</th>\n",
       "      <th>Spark</th>\n",
       "      <th>Java</th>\n",
       "      <th>Scala</th>\n",
       "      <th>recruiter</th>\n",
       "      <th>state_encoded</th>\n",
       "      <th>salary_section</th>\n",
       "      <th>salary_section_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fantastic organisation seeks experienced Insig...</td>\n",
       "      <td>2</td>\n",
       "      <td>90000</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n  \\n    \\n    \\n      Insights Analyst – Onl...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(100000.0, 110000.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This role requires an individual with strong c...</td>\n",
       "      <td>2</td>\n",
       "      <td>90000</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n  \\n    \\n    \\n      Credit Risk Analyst \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(90000.0, 100000.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>One of Australia's leading financial service p...</td>\n",
       "      <td>2</td>\n",
       "      <td>110000</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n  \\n    \\n    Data Analytics Recruitment Sol...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(110000.0, 120000.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Postdoctoral researcher in molecular evolution...</td>\n",
       "      <td>2</td>\n",
       "      <td>71509</td>\n",
       "      <td>90215</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n  \\n    \\n    \\n      Postdoctoral Fellow \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(80000.0, 90000.0]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Postdoctoral researcher in molecular evolution...</td>\n",
       "      <td>2</td>\n",
       "      <td>71509</td>\n",
       "      <td>90215</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n  \\n    \\n    \\n      Postdoctoral Fellow \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(80000.0, 90000.0]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  jobClassification  state  \\\n",
       "0           0                  0      1   \n",
       "1           1                  1      1   \n",
       "2           2                  1      1   \n",
       "3           3                  2      0   \n",
       "4           4                  3      0   \n",
       "\n",
       "                                              teaser  workType  min_salary  \\\n",
       "0  Fantastic organisation seeks experienced Insig...         2       90000   \n",
       "1  This role requires an individual with strong c...         2       90000   \n",
       "2  One of Australia's leading financial service p...         2      110000   \n",
       "3  Postdoctoral researcher in molecular evolution...         2       71509   \n",
       "4  Postdoctoral researcher in molecular evolution...         2       71509   \n",
       "\n",
       "   max_salary  isRightToWorkRequired  \\\n",
       "0      120000                      0   \n",
       "1      110000                      0   \n",
       "2      120000                      1   \n",
       "3       90215                      0   \n",
       "4       90215                      0   \n",
       "\n",
       "                                   desktopAdTemplate  Python  ...  SAS  \\\n",
       "0  \\n  \\n    \\n    \\n      Insights Analyst – Onl...       0  ...    0   \n",
       "1  \\n  \\n    \\n    \\n      Credit Risk Analyst \\n...       0  ...    1   \n",
       "2  \\n  \\n    \\n    Data Analytics Recruitment Sol...       1  ...    1   \n",
       "3  \\n  \\n    \\n    \\n      Postdoctoral Fellow \\n...       0  ...    0   \n",
       "4  \\n  \\n    \\n    \\n      Postdoctoral Fellow \\n...       0  ...    0   \n",
       "\n",
       "   Matlab  Hadoop  Spark  Java  Scala  recruiter  state_encoded  \\\n",
       "0       0       0      0     0      0          1              1   \n",
       "1       0       0      0     0      0          1              1   \n",
       "2       0       0      0     0      0          1              1   \n",
       "3       0       0      0     1      0          0              0   \n",
       "4       0       0      0     1      0          0              0   \n",
       "\n",
       "         salary_section  salary_section_enc  \n",
       "0  (100000.0, 110000.0]                 0.0  \n",
       "1   (90000.0, 100000.0]                 1.0  \n",
       "2  (110000.0, 120000.0]                 2.0  \n",
       "3    (80000.0, 90000.0]                 3.0  \n",
       "4    (80000.0, 90000.0]                 3.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4fc10",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1fc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['teaser']= df['teaser'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4920719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desktopAdTemplate']= df['desktopAdTemplate'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab453253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  jobClassification  state  workType  min_salary  max_salary  \\\n",
      "0           0                  0      1         2       90000      120000   \n",
      "1           1                  1      1         2       90000      110000   \n",
      "2           2                  1      1         2      110000      120000   \n",
      "3           3                  2      0         2       71509       90215   \n",
      "4           4                  3      0         2       71509       90215   \n",
      "\n",
      "   isRightToWorkRequired  Python  SQL  R  ...  6803  6804  6805  6806  6807  \\\n",
      "0                      0       0    1  1  ...   0.0   0.0   0.0   0.0   0.0   \n",
      "1                      0       0    1  1  ...   0.0   0.0   0.0   0.0   0.0   \n",
      "2                      1       1    1  1  ...   0.0   0.0   0.0   0.0   0.0   \n",
      "3                      0       0    0  0  ...   0.0   0.0   0.0   0.0   0.0   \n",
      "4                      0       0    0  0  ...   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   6808  6809  6810  6811 6812  \n",
      "0   0.0   0.0   0.0   0.0  0.0  \n",
      "1   0.0   0.0   0.0   0.0  0.0  \n",
      "2   0.0   0.0   0.0   0.0  0.0  \n",
      "3   0.0   0.0   0.0   0.0  0.0  \n",
      "4   0.0   0.0   0.0   0.0  0.0  \n",
      "\n",
      "[5 rows x 7766 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Clean the text data\n",
    "df['teaser'] = df['teaser'].str.replace('[^\\w\\s]', '') # Remove punctuation\n",
    "df['desktopAdTemplate'] = df['desktopAdTemplate'].str.replace('[^\\w\\s]', '') # Remove punctuation\n",
    "df['teaser'] = df['teaser'].str.replace('\\d+', '') # Remove digits\n",
    "df['desktopAdTemplate'] = df['desktopAdTemplate'].str.replace('\\d+', '') # Remove digits\n",
    "\n",
    "# Normalize the text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['teaser'] = df['teaser'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stop_words]))\n",
    "df['desktopAdTemplate'] = df['desktopAdTemplate'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stop_words]))\n",
    "\n",
    "# Tokenize the text data\n",
    "df['teaser'] = df['teaser'].apply(lambda x: word_tokenize(x))\n",
    "df['desktopAdTemplate'] = df['desktopAdTemplate'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Apply stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['teaser'] = df['teaser'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df['desktopAdTemplate'] = df['desktopAdTemplate'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# # Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "teaser_tfidf = vectorizer.fit_transform(df['teaser'].apply(lambda x: ' '.join(x)))\n",
    "desktopAdTemplate_tfidf = vectorizer.fit_transform(df['desktopAdTemplate'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# # Concatenate the TF-IDF vectors with the original dataframe\n",
    "df = pd.concat([df.drop(['teaser', 'desktopAdTemplate'], axis=1), pd.DataFrame(teaser_tfidf.toarray()), pd.DataFrame(desktopAdTemplate_tfidf.toarray())], axis=1)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b40d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 7766)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8d8254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([           'Unnamed: 0',     'jobClassification',\n",
       "                       'state',              'workType',\n",
       "                  'min_salary',            'max_salary',\n",
       "       'isRightToWorkRequired',                'Python',\n",
       "                         'SQL',                     'R',\n",
       "       ...\n",
       "                          6803,                    6804,\n",
       "                          6805,                    6806,\n",
       "                          6807,                    6808,\n",
       "                          6809,                    6810,\n",
       "                          6811,                    6812],\n",
       "      dtype='object', length=7766)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28cfaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0','state_encoded','min_salary','max_salary','salary_section'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7d9b54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    'jobClassification',                 'state',\n",
       "                    'workType', 'isRightToWorkRequired',\n",
       "                      'Python',                   'SQL',\n",
       "                           'R',               'Tableau',\n",
       "                         'SAS',                'Matlab',\n",
       "       ...\n",
       "                          6803,                    6804,\n",
       "                          6805,                    6806,\n",
       "                          6807,                    6808,\n",
       "                          6809,                    6810,\n",
       "                          6811,                    6812],\n",
       "      dtype='object', length=7761)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e2b330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 7761)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd7b98",
   "metadata": {},
   "source": [
    "### Read csv file to the same split for other experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e68dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url_x_train = 'https://raw.githubusercontent.com/wongwara/Jobseeker_Baymax/main/Final/data%20splitted/X_train.csv'\n",
    "file_url_x_test = 'https://raw.githubusercontent.com/wongwara/Jobseeker_Baymax/main/Final/data%20splitted/X_test.csv'\n",
    "file_url_y_train = 'https://raw.githubusercontent.com/wongwara/Jobseeker_Baymax/main/Final/data%20splitted/y_train.csv'\n",
    "file_url_y_test = 'https://raw.githubusercontent.com/wongwara/Jobseeker_Baymax/main/Final/data%20splitted/y_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70c2e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(file_url_x_train)\n",
    "x_test = pd.read_csv(file_url_x_test)\n",
    "y_train = pd.read_csv(file_url_y_train)\n",
    "y_test = pd.read_csv(file_url_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66146422",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop('Unnamed: 0', axis = 1)\n",
    "y_test = y_test.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770fc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 7761) (128, 7761) (510, 1) (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f51bfc",
   "metadata": {},
   "source": [
    "### Train model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c3a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d2942",
   "metadata": {},
   "source": [
    "Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fd049ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score : 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_pred = log_reg.predict(x_train)\n",
    "train_acc_score = accuracy_score(y_train, train_pred)\n",
    "print('Training Accuracy Score :', train_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5529425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy Score : 0.375\n"
     ]
    }
   ],
   "source": [
    "test_pred = log_reg.predict(x_test)\n",
    "test_acc_score = accuracy_score(y_test, test_pred)\n",
    "print('Testing Accuracy Score :', test_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a75a8",
   "metadata": {},
   "source": [
    "F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ce9a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f1 Score : 0.37464600890200045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "train_f1_score = f1_score(y_train, train_pred, average='macro')\n",
    "print('Training f1 Score :', train_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7991086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing f1 Score : 0.36236322198230747\n"
     ]
    }
   ],
   "source": [
    "test_f1_score = f1_score(y_test, test_pred, average='macro')\n",
    "print('Testing f1 Score :', test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba8e281",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8c7efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                                        'max_iter': [100, 200, 500],\n",
       "                                        'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist ={'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "             'penalty': ['l1', 'l2'],\n",
    "             'max_iter': [100, 200, 500]\n",
    "            }\n",
    "random_search_log = RandomizedSearchCV(log_reg, param_distributions = param_dist)\n",
    "random_search_log.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebdd9033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'max_iter': 200, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "best_params_random = random_search_log.best_params_\n",
    "best_score_random = random_search_log.best_score_\n",
    "print(best_params_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d64842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_random = LogisticRegression(**best_params_random)\n",
    "best_model_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3ce68",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19d460ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hyperparameter tuning - Random Search 0.4725490196078431\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_random = best_model_random.predict(x_train)\n",
    "train_acc_score_random = accuracy_score(y_train, y_train_pred_random)\n",
    "print('Training Hyperparameter tuning - Random Search', train_acc_score_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbeac503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Hyperparameter tuning - Random Search 0.3828125\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_random = best_model_random.predict(x_test)\n",
    "test_acc_score_random = accuracy_score(y_test, y_test_pred_random)\n",
    "print('Testing Hyperparameter tuning - Random Search', test_acc_score_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c23e7",
   "metadata": {},
   "source": [
    "#### f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60c69e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hyperparameter tuning - Random Search 0.4143088731100285\n"
     ]
    }
   ],
   "source": [
    "train_f1_score_random = f1_score(y_train, y_train_pred_random, average='macro')\n",
    "print('Training Hyperparameter tuning - Random Search', train_f1_score_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c26d3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Hyperparameter tuning - Random Search 0.36738162097437593\n"
     ]
    }
   ],
   "source": [
    "test_f1_score_random = f1_score(y_test, y_test_pred_random, average='macro')\n",
    "print('Testing Hyperparameter tuning - Random Search', test_f1_score_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
